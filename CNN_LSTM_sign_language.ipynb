{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Flatten, TimeDistributed, Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 50\n",
      "['drogueria', 'preocupar', 'jugar', 'jardin', 'olvidar', 'ducha', 'computador', 'domingo', 'apoyar', 'ahora', 'feliz', 'recordar', 'transmilenio', 'depender', 'gustar', 'miedo', 'apartamento', 'llevar', 'banco', 'furioso', 'aspiradora', 'calle', 'escalera', 'mareo', 'besar', 'vida', 'doler', 'problema', 'salir', 'empezar', 'futbol', 'telefono', 'radiografia', 'botella', 'invitar', 'banio', 'necesitar', 'discoteca', 'confundido', 'paciencia', 'celular', 'hospital', 'querer', 'zapato', 'cuchara', 'entender', 'saber', 'camion', 'oficina', 'bailar']\n"
     ]
    }
   ],
   "source": [
    "frames = 100\n",
    "root_folder = '/home/JulioCesar/sign_language/cnn_lstm'\n",
    "classes_folder = os.path.join(root_folder, 'frames')\n",
    "classes_list = os.listdir(classes_folder)\n",
    "classes = len(classes_list)\n",
    "\n",
    "dict_path = os.path.join(root_folder, 'dict')\n",
    "encoding_path = os.path.join(dict_path, 'encoding.json')\n",
    "decoding_path = os.path.join(dict_path, 'decoding.json')\n",
    "\n",
    "print('Number of classes: {}'.format(classes))\n",
    "print(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Un-comment code below to create dictionary\n",
    "# # it is only required when new word is registered\n",
    "# # or existing word is removed\n",
    "# encoding = {}\n",
    "# decoding = {}\n",
    "# for ind, word in enumerate(classes_list):\n",
    "#     # print('Current {}%'.format((ind/float(classes)) * 100))\n",
    "#     encoding[ind] = word\n",
    "#     decoding[word] = ind\n",
    "\n",
    "# print('encoding has {} items'.format(len(encoding.keys())))\n",
    "# print(encoding.keys())\n",
    "# print('decoding has {} items'.format(len(decoding.keys())))\n",
    "# print(decoding.keys())\n",
    "# print('Test encoding: {} is {}'.format(21, encoding[21]))\n",
    "# print('Test decoding: {} is {}'.format('calle', decoding['calle']))\n",
    "\n",
    "# json_file = json.dumps(encoding)\n",
    "# f = open(encoding_path, 'w')\n",
    "# f.write(json_file)\n",
    "# f.close()\n",
    "\n",
    "# json_file = json.dumps(decoding)\n",
    "# f = open(decoding_path, 'w')\n",
    "# f.write(json_file)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding has 50 items\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "Test encoding: 21 is calle\n",
      "decoding has 50 items\n",
      "dict_keys(['doler', 'problema', 'apoyar', 'bailar', 'futbol', 'feliz', 'celular', 'salir', 'gustar', 'aspiradora', 'computador', 'cuchara', 'miedo', 'ahora', 'llevar', 'querer', 'saber', 'paciencia', 'hospital', 'discoteca', 'oficina', 'recordar', 'empezar', 'furioso', 'olvidar', 'drogueria', 'zapato', 'invitar', 'banco', 'preocupar', 'calle', 'radiografia', 'ducha', 'botella', 'jugar', 'necesitar', 'banio', 'confundido', 'jardin', 'camion', 'transmilenio', 'depender', 'mareo', 'domingo', 'telefono', 'entender', 'apartamento', 'besar', 'vida', 'escalera'])\n",
      "Test decoding: calle is 21\n"
     ]
    }
   ],
   "source": [
    "# 50 videos\n",
    "# min: 59, max: 125\n",
    "\n",
    "encoding = {}\n",
    "decoding = {}\n",
    "with open(encoding_path, 'r') as f:\n",
    "    encoding_tmp = json.load(f)\n",
    "    for key in encoding_tmp.keys():\n",
    "        encoding[int(key)] = encoding_tmp[key]\n",
    "\n",
    "with open(decoding_path, 'r') as f:\n",
    "    decoding = json.load(f)    \n",
    "\n",
    "print('encoding has {} items'.format(len(encoding.keys())))\n",
    "print(encoding.keys())\n",
    "print('Test encoding: {} is {}'.format('21', encoding[21]))\n",
    "\n",
    "print('decoding has {} items'.format(len(decoding.keys())))\n",
    "print(decoding.keys())\n",
    "print('Test decoding: {} is {}'.format('calle', decoding['calle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "----------------\n",
      "11\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_labels = to_categorical(list(encoding.keys()))\n",
    "print(one_hot_labels[:3])\n",
    "# print(one_hot_labels[2])\n",
    "print('----------------')\n",
    "print(decoding['recordar'])\n",
    "print(one_hot_labels[decoding['recordar']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
    "from keras.applications.mobilenet import preprocess_input as preprocess_input_mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 160\n",
    "\n",
    "def get_img_from_folder(category):\n",
    "    imgs_array = []\n",
    "    items_per_category = os.listdir(os.path.join(classes_folder, category))\n",
    "    sample = random.choice(items_per_category)\n",
    "    len_imgs = len(os.listdir(os.path.join(classes_folder, category, sample)))\n",
    "    # print('len_imgs:', len_imgs)\n",
    "    # padding/crop to 100 images\n",
    "    crop = False\n",
    "    pad = False\n",
    "    match = False\n",
    "    \n",
    "    difference = 0\n",
    "    if len_imgs == frames:\n",
    "        match = True\n",
    "    elif len_imgs > frames:\n",
    "        crop = True\n",
    "        difference = int((len_imgs - frames)/2)\n",
    "    else:\n",
    "        pad = True\n",
    "        difference = int((frames - len_imgs)/2)\n",
    "        \n",
    "    counter = 0\n",
    "    for num_img in range(frames):\n",
    "        if pad:\n",
    "            if num_img < difference or num_img >= (frames - difference - 1):\n",
    "                # add blank image\n",
    "                blank_image = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "                imgs_array.append(blank_image)\n",
    "                # cv2.imwrite(os.path.join(root_folder, 'test', category + '_' + str(num_img) + '.jpg'), blank_image)\n",
    "                continue\n",
    "            else:\n",
    "                img_item = category + '_' + str(counter) + '.jpg'\n",
    "                counter += 1\n",
    "        elif match:\n",
    "            img_item = category + '_' + str(num_img) + '.jpg'\n",
    "        elif crop:\n",
    "            img_item = category + '_' + str(num_img + difference) + '.jpg'\n",
    "        \n",
    "        img_path = os.path.join(classes_folder, category, sample, img_item)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        imgs_array.append(img)\n",
    "        # cv2.imwrite(os.path.join(root_folder, 'test', category + '_' + str(num_img) + '.jpg'), img)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        for num_img in range(len_imgs):\n",
    "            img_item = category + '_' + str(num_img) + '.jpg'\n",
    "            img_path = os.path.join(classes_folder, category, sample, img_item)\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgs_array.append(img)\n",
    "        '''        \n",
    "    # return np.array(imgs_array)\n",
    "    return imgs_array\n",
    "    \n",
    "\n",
    "def generate_train_batch(batch_size = 8):\n",
    "    while True:\n",
    "        random_items = random.sample(list(encoding.keys()), batch_size)\n",
    "        X_data = []\n",
    "        Y_data = []\n",
    "        for item in random_items:\n",
    "            category = encoding[item]\n",
    "            # print('category:', category)\n",
    "            img = get_img_from_folder(category)\n",
    "            img = cv2.normalize(np.float32(img), None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            X_data.append(img)\n",
    "            Y_data.append(one_hot_labels[item])\n",
    "            \n",
    "        X_data = np.array(X_data)\n",
    "        Y_data = np.array(Y_data)\n",
    "        # X_data /= 255. #preprocess_input_mobilenet(X_data)\n",
    "        yield (X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_train_batch(batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100, 160, 160, 3) (8, 50)\n",
      "0.9612069\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    my_x, my_y = next(train_gen)\n",
    "    print(my_x.shape, my_y.shape)\n",
    "    print(np.max(my_x[0][50]))\n",
    "    print(np.min(my_x[0][50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs = Input(shape = (frames, IMG_SIZE, IMG_SIZE, 3))\\ncnn_base = MobileNet(include_top = False, weights=\\'imagenet\\', input_shape = (IMG_SIZE, IMG_SIZE, 3))\\n\\ncnn_out = GlobalAveragePooling2D()(cnn_base.output)\\ncnn = Model(inputs=cnn_base.input, outputs=cnn_out)\\n# cnn = Model(inputs=cnn_base.input, outputs=cnn_base.output)\\nencoded_frames = TimeDistributed(cnn)(inputs)\\nencoded_sequence = LSTM(128)(encoded_frames)\\n\\nhidden_layer = Dense(256, activation=\"relu\")(encoded_sequence)\\noutputs = Dense(classes, activation=\"softmax\")(hidden_layer)\\nmodel = Model([inputs], outputs)\\n\\nmodel.compile(optimizer=\\'adam\\', loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "inputs = Input(shape = (frames, IMG_SIZE, IMG_SIZE, 3))\n",
    "cnn_base = MobileNet(include_top = False, weights='imagenet', input_shape = (IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "cnn = Model(inputs=cnn_base.input, outputs=cnn_out)\n",
    "# cnn = Model(inputs=cnn_base.input, outputs=cnn_base.output)\n",
    "encoded_frames = TimeDistributed(cnn)(inputs)\n",
    "encoded_sequence = LSTM(128)(encoded_frames)\n",
    "\n",
    "hidden_layer = Dense(256, activation=\"relu\")(encoded_sequence)\n",
    "outputs = Dense(classes, activation=\"softmax\")(hidden_layer)\n",
    "model = Model([inputs], outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "'''\n",
    "# # input_layer = Input(shape=(None,224,224,3))\n",
    "# # td = TimeDistributed(cnn)(input_layer)\n",
    "# # model = Model(input_layer, td)\n",
    "# # # x = TimeDistributed(Flatten())(x)\n",
    "# # model = LSTM(256)(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(2, (2,2), activation= 'relu' ), input_shape=(None, IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(classes, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, None, 159, 159, 2) 26        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 79, 79, 2)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 12482)       0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                2506600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "=================================================================\n",
      "Total params: 2,509,176\n",
      "Trainable params: 2,509,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks as callbacks\n",
    "callbacks_list = [callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(root_folder, 'exported_models', 'V4', 'sign-model-{epoch:02d}-{acc:.2f}.h5'),\n",
    "        monitor='accuracy',\n",
    "        save_best_only=False)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 866s 3s/step - loss: 2.5542 - acc: 0.4500\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 863s 3s/step - loss: 1.0213 - acc: 0.9090\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 835s 3s/step - loss: 0.4205 - acc: 0.9895\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 877s 4s/step - loss: 0.1596 - acc: 0.9995\n",
      "Epoch 5/20\n",
      " 13/250 [>.............................] - ETA: 14:33 - loss: 0.1128 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-17f7fac80b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/gpu-py3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu-py3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu-py3/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu-py3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=250,\n",
    "                              epochs=20,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
